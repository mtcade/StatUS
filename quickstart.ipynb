{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de88c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hexathello import autoPlayer, engine, jable, printing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from os import path, remove\n",
    "\n",
    "# Hexathello can be played as a game, or played by AI to train\n",
    "# We're unlikely to intialize a Hexathello Engine directly. Instead, use ``autoPlayer`` to setup a game\n",
    "#   for AI to play\n",
    "\n",
    "# -- Settings\n",
    "game_size: int = 5\n",
    "player_count: int = 2\n",
    "\n",
    "# First, choose our AIs. The RandomHexAgent is the dumbest, picking randomly from legal moves.\n",
    "# Indexing begins with 0 as it should. As a result, the 'second' player is \"Player 1\"; use the latter notation\n",
    "\n",
    "ai_0: autoPlayer.HexAgent = autoPlayer.RandomHexAgent(\n",
    "    size = game_size,\n",
    "    player_count = player_count,\n",
    "    player_id = 0\n",
    ")\n",
    "    \n",
    "ai_1: autoPlayer.HexAgent = autoPlayer.RandomHexAgent(\n",
    "    size = game_size,\n",
    "    player_count = player_count,\n",
    "    player_id = 1\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99b02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have them play eachother\n",
    "literalHistory: jable.JyFrame = autoPlayer.runHexathello_withAgents(\n",
    "    agents = [ai_0, ai_1],\n",
    "    size = game_size,\n",
    "    logging_level = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb9fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a literal history shows the state at turn from the board's point of view. However, to do machine learning,\n",
    "#  we need to shift the encoding of state as if it were from player 0's point of view. Otherwise, we would need\n",
    "#  a different network for each player index; 2, 3 or 6 times as many\n",
    "\n",
    "povHistory: jable.JyFrame = autoPlayer.povHistory_from_literalHistory(\n",
    "    literalHistory\n",
    ")\n",
    "\n",
    "printing.prettyprint( povHistory )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f7bdf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early end, no move for any player\n",
      "RESULT: 21 - 21; Tie among 0, 1\n",
      "# Game done\n",
      "{'winner': None, 'turn_index': 36, 'size': 5, 'game_complete': True, 'empty_count': 19, 'player_count': 2, 'current_player': 0, 'scores': [21, 21]}\n",
      "# Encode/decode success\n"
     ]
    }
   ],
   "source": [
    "# Save this to the disk to be used for future learning. We encode the state and play vectors as integers\n",
    "povHistory_encoded: jable.JyFrame = autoPlayer.history_asInt(\n",
    "    povHistory\n",
    ")\n",
    "\n",
    "# Test we encode and decode appropriately\n",
    "if True:\n",
    "    povHistory_decoded: jable.JyFrame = autoPlayer.history_fromInt(\n",
    "        povHistory_encoded\n",
    "    )\n",
    "    _povHistory_i: dict[ str, any ] = {}\n",
    "    _povHistory_decoded_i: dict[ str, any ] = {}\n",
    "    \n",
    "    assert len( povHistory ) == len( povHistory_decoded )\n",
    "\n",
    "    for i in range( len( povHistory ) ):\n",
    "        _povHistory_i: dict = povHistory[i]\n",
    "        _povHistory_decoded_i: dict = povHistory_decoded[i]\n",
    "\n",
    "        if not len( _povHistory_i[\"board_state\"] ) == len( _povHistory_decoded_i[\"board_state\"] ):\n",
    "            print(\"# Incongruity in len 'board_state' at row index={}\".format(i))\n",
    "            print( _povHistory_i )\n",
    "            print( _povHistory_decoded_i )\n",
    "            raise Exception(\"Len Incongruity\")\n",
    "        #\n",
    "\n",
    "        if not np.all(\n",
    "            _povHistory_i[\"board_state\"] == _povHistory_decoded_i[\"board_state\"]\n",
    "        ):\n",
    "            print(\"# Incongruity in 'board_state' at row index={}\".format(i))\n",
    "            print( _povHistory_i )\n",
    "            print( _povHistory_decoded_i )\n",
    "            raise Exception(\"Incongruity\")\n",
    "        #\n",
    "\n",
    "        if not len( _povHistory_i[\"player_action\"] ) == len( _povHistory_decoded_i[\"player_action\"] ):\n",
    "            print(\"# Incongruity in len 'player_action' at row index={}\".format(i))\n",
    "            print( _povHistory_i )\n",
    "            print( _povHistory_decoded_i )\n",
    "            raise Exception(\"Len Incongruity\")\n",
    "        #\n",
    "\n",
    "        if not np.all(\n",
    "            _povHistory_i[\"player_action\"] == _povHistory_decoded_i[\"player_action\"]\n",
    "        ):\n",
    "            print(\"# Incongruity in 'player_action' at row index={}\".format(i))\n",
    "            print( _povHistory_i )\n",
    "            print( _povHistory_decoded_i )\n",
    "            raise Exception(\"Incongruity\")\n",
    "        #    \n",
    "    #/for i in range( len( povHistory ) )\n",
    "    \n",
    "    del _povHistory_decoded_i\n",
    "    del _povHistory_i\n",
    "    del povHistory_decoded\n",
    "    \n",
    "    print(\"# Encode/decode success\")\n",
    "#/if True\n",
    "\n",
    "# Prepare the save location for future learning\n",
    "histories_dir: str = path.join(\n",
    "    'data',\n",
    "    'histories'\n",
    ")\n",
    "assert path.isdir(\n",
    "    histories_dir\n",
    ")\n",
    "\n",
    "test_data_name: str = 'random_size-{}_players-{}'.format(\n",
    "    game_size, player_count\n",
    ")\n",
    "\n",
    "# Make sure it's a new file\n",
    "while path.isfile(\n",
    "    path.join(\n",
    "        histories_dir,\n",
    "        '{}.json'.format( test_data_name )\n",
    "    )\n",
    "):\n",
    "       test_data_name = '{}_TEMP'.format( test_data_name )\n",
    "#\n",
    "\n",
    "test_data_path: str = path.join(\n",
    "    histories_dir,\n",
    "    '{}.json'.format( test_data_name )\n",
    ")\n",
    "povHistory_encoded.write_file(\n",
    "    test_data_path\n",
    ")\n",
    "\n",
    "# Read the data from disk to learn from\n",
    "# (We could use povHistory directly in this particular case)\n",
    "povHistory_fromDisk: jable.JyFrame = jable.read_file(\n",
    "    test_data_path\n",
    ")\n",
    "\n",
    "# Decode the state and play vectors from integers to numpy arrays\n",
    "povHistory_decoded: jable.JyFrame = autoPlayer.history_fromInt(\n",
    "    povHistory_fromDisk\n",
    ")\n",
    "\n",
    "# We want to train a Keras Neural Network on the data we have.\n",
    "# The input size is the length of a state vector\n",
    "# The output size is the length of the play vector\n",
    "# Take both from the first row\n",
    "input_size: int = len( povHistory_decoded[0,'board_state'] )\n",
    "output_size: int = len( povHistory_decoded[0, 'player_action'] )\n",
    "\n",
    "# The `KerasHexAgent` subclass of `HexAgent` has a `brain` property; this is the neural network\n",
    "# We could in fact us any objects conforming to the `PredictionModel` protocol, which has methods:\n",
    "#   - fit()\n",
    "#   - predict()\n",
    "#   - call()\n",
    "#\n",
    "# We're going to train it on the random choices\n",
    "import tensorflow as tf\n",
    "brain_input = tf.keras.layers.Input(\n",
    "    shape = (input_size,),\n",
    "    name = 'keras_tensor'\n",
    ")\n",
    "\n",
    "# Get creative with architecture\n",
    "brain_next = tf.keras.layers.Dense(\n",
    "    input_size**2,\n",
    "    activation = 'relu'\n",
    ")( brain_input )\n",
    "\n",
    "brain_next = tf.keras.layers.Dense(\n",
    "    input_size**2,\n",
    "    activation = 'relu'\n",
    ")\n",
    "\n",
    "brain_output = tf.keras.layers.Dense(\n",
    "    output_size,\n",
    "    activation = 'sigmoid'\n",
    ")\n",
    "\n",
    "brain_model: tf.keras.Model = tf.keras.Model(\n",
    "    brain_input,\n",
    "    brain_output\n",
    ")\n",
    "    \n",
    "# Choose your learning rate and optimizer. Adam is probably good for the latter.\n",
    "# You most likely want Binary Cross Entropy\n",
    "brain_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate = 0.005\n",
    "    ),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    ")\n",
    "\n",
    "# Init the AI Agent\n",
    "ai_keras: autoPlayer.KerasHexAgent = autoPlayer.KerasHexAgent(\n",
    "    size = game_size,\n",
    "    player_count = player_count,\n",
    "    brain = brain_model,\n",
    "    player_id = None,\n",
    "    ai_id = 'Keras_alpha_0'\n",
    ")\n",
    "\n",
    "\n",
    "assert path.isfile( test_data_path )\n",
    "\n",
    "os.remove( test_data_path )\n",
    "assert not path.isfile( test_data_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4876e27b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 env",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
