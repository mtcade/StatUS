{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c0ecbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hexathello.aiPlayers as aiPlayers\n",
    "import hexathello.autoPlayer as autoPlayer\n",
    "import hexathello.engine as engine\n",
    "import hexathello.history as history\n",
    "import hexathello.jable as jable\n",
    "import hexathello.printing as printing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from os import path\n",
    "\n",
    "# -- Settings\n",
    "game_size: int = 5\n",
    "player_count: int = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d7bbad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to train a KerasHexAgent. To do this, we use data we created in `quickstart_recording_data.ipynb`\n",
    "\n",
    "history_dir: str = path.join(\n",
    "    'data',\n",
    "    'history',\n",
    "    'examples'\n",
    ")\n",
    "assert path.isdir(\n",
    "    history_dir\n",
    ")\n",
    "\n",
    "baseline_data_path: str = path.join(\n",
    "    history_dir,\n",
    "    'greendom_size-{}_players-{}.json'.format(\n",
    "        game_size, player_count\n",
    "    )\n",
    ")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b35b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Reading history from data/history/examples/greendom_size-5_players-2.json\n"
     ]
    }
   ],
   "source": [
    "# Read the data from disk to learn from\n",
    "print(\"# Reading history from {}\".format( baseline_data_path ) )\n",
    "history_fromDisk: jable.JyFrame = jable.read_file(\n",
    "    baseline_data_path\n",
    ")\n",
    "\n",
    "# Decode the state, option, and play vectors from integers to numpy arrays\n",
    "history_decoded: jable.JyFrame = history.history_fromInt(\n",
    "    history_fromDisk\n",
    ")\n",
    "\n",
    "assert len( history_decoded ) >= 20000\n",
    "    \n",
    "# Make it PoV 0 to appropriately learn\n",
    "povHistory: jable.JyFrame = history.povHistory_from_literalHistory(\n",
    "    history_decoded\n",
    ")\n",
    "\n",
    "del history_decoded\n",
    "del history_fromDisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f30778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to train a Keras Neural Network on the data we have.\n",
    "# The input size is the length of a state vector\n",
    "# The output size is the length of the play vector\n",
    "# Take both from the first row\n",
    "input_size: int = len( povHistory[0,'board_state'] )\n",
    "output_size: int = len( povHistory[0, 'player_action'] )\n",
    "\n",
    "# The `KerasHexAgent` subclass of `HexAgent` has a `brain` property; this is the neural network\n",
    "# We could in fact us any objects conforming to the `PredictionModel` protocol, which has methods:\n",
    "#   - fit()\n",
    "#   - predict()\n",
    "#   - call()\n",
    "#\n",
    "# We're going to train it on the Greendom data\n",
    "# Match the input to a board state vector\n",
    "import tensorflow as tf\n",
    "\n",
    "ai_keras_id: str = 'kha_alpha_size-{}_players-{}_0'.format(\n",
    "    game_size, player_count\n",
    ")\n",
    "\n",
    "ai_keras_path: str = path.join(\n",
    "    'data',\n",
    "    'ai',\n",
    "    'examples',\n",
    "    '{}.keras'.format( ai_keras_id )\n",
    ")\n",
    "\n",
    "brain_model: tf.keras.Model\n",
    "if path.isfile( ai_keras_path ):\n",
    "    brain_model = tf.keras.models.load_model( ai_keras_path )\n",
    "#\n",
    "else:\n",
    "    brain_input = tf.keras.layers.Input(\n",
    "        shape = (input_size,),\n",
    "        name = 'keras_tensor'\n",
    "    )\n",
    "\n",
    "    # Get creative with architecture on the inside\n",
    "    brain_next = tf.keras.layers.Dense(\n",
    "        input_size*2,\n",
    "        activation = 'relu'\n",
    "    )( brain_input )\n",
    "\n",
    "    brain_next = tf.keras.layers.Dense(\n",
    "        input_size*2,\n",
    "        activation = 'relu'\n",
    "    )( brain_next )\n",
    "\n",
    "    # Make the output size equal to the move vector size\n",
    "    brain_output = tf.keras.layers.Dense(\n",
    "        output_size,\n",
    "        activation = 'sigmoid'\n",
    "    )( brain_next )\n",
    "\n",
    "    brain_model: tf.keras.Model = tf.keras.Model(\n",
    "        brain_input,\n",
    "        brain_output\n",
    "    )\n",
    "\n",
    "    # Choose your learning rate and optimizer. Adam is probably good for the latter.\n",
    "    # You most likely want Binary Cross Entropy. Learning rate 0.0001 to 0.01 is likely fine\n",
    "    brain_model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate = 0.005\n",
    "        ),\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    )\n",
    "#/if path.isfile( ai_keras_path )\n",
    "\n",
    "# Init the AI Agent\n",
    "ai_keras: aiPlayers.KerasHexAgent = aiPlayers.KerasHexAgent(\n",
    "    size = game_size,\n",
    "    player_count = player_count,\n",
    "    brain = brain_model,\n",
    "    player_id = None,\n",
    "    ai_id = ai_keras_id,\n",
    "    p_random = 0.2\n",
    ")\n",
    "\n",
    "# Set the checkpoint to save\n",
    "ai_keras_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=ai_keras_path,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "ai_keras.train(\n",
    "    game_history = povHistory,\n",
    "    epochs = 10,\n",
    "    callbacks = [ ai_keras_checkpoint_callback ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42296d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the network\n",
    "ai_keras.brain.summary()\n",
    "\n",
    "\n",
    "# Get creative with the brain you use to train a KerasHexAgent, and try writing a subclass changing:\n",
    "#   .prep_training_history(...)\n",
    "#   .chooseMove(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b305a078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 env",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
